{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37333a51-174a-412b-83e4-9fcf78522607",
   "metadata": {},
   "source": [
    "# Luangwa Basin Time Series Analysis for MSC IWRM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d786493-258d-4c11-863c-3a4848070249",
   "metadata": {},
   "source": [
    "## Preliminary processing of data\n",
    "Time is the most important thing in a time-series. Therefore it is important to convert the data into the appropriate format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d99783-8d56-4372-8322-56f6101f2805",
   "metadata": {},
   "source": [
    "### 1. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6d027-017a-42c8-906d-9a625fe9b555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947741e7-613f-44c0-874e-6acb743b30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.graphics.tsaplots as sgt\n",
    "import statsmodels.tsa.stattools as sts\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import seaborn as sns\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce4a2d3-e1e4-4687-8e57-2786e57eaa7e",
   "metadata": {},
   "source": [
    "### 2. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c616af4d-6fbc-4381-a8ef-8d6ae2dac8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_csv_data = pd.read_csv('2013-18MOD16A2Station_Serenje2.csv')\n",
    "df_comp = raw_csv_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6368010-43be-4620-b816-4a46445b5761",
   "metadata": {},
   "source": [
    "### 3. Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d417c9e-2225-4c47-ba9a-7cb77275051c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Satellite_ET</th>\n",
       "      <th>ScaledS_ET</th>\n",
       "      <th>Station_ET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2013</td>\n",
       "      <td>263.876</td>\n",
       "      <td>26.388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/2013</td>\n",
       "      <td>324.463</td>\n",
       "      <td>32.446</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/1/2013</td>\n",
       "      <td>355.000</td>\n",
       "      <td>35.500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/1/2013</td>\n",
       "      <td>262.270</td>\n",
       "      <td>26.227</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/1/2013</td>\n",
       "      <td>188.725</td>\n",
       "      <td>18.873</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6/1/2013</td>\n",
       "      <td>128.474</td>\n",
       "      <td>12.847</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7/1/2013</td>\n",
       "      <td>108.482</td>\n",
       "      <td>10.848</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8/1/2013</td>\n",
       "      <td>74.753</td>\n",
       "      <td>7.475</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9/1/2013</td>\n",
       "      <td>65.583</td>\n",
       "      <td>6.558</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10/1/2013</td>\n",
       "      <td>107.078</td>\n",
       "      <td>10.708</td>\n",
       "      <td>-4.102158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11/1/2013</td>\n",
       "      <td>156.447</td>\n",
       "      <td>15.645</td>\n",
       "      <td>17.128312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12/1/2013</td>\n",
       "      <td>215.078</td>\n",
       "      <td>21.508</td>\n",
       "      <td>63.766344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/1/2014</td>\n",
       "      <td>260.057</td>\n",
       "      <td>26.006</td>\n",
       "      <td>67.850113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2/1/2014</td>\n",
       "      <td>307.218</td>\n",
       "      <td>30.722</td>\n",
       "      <td>70.190364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3/1/2014</td>\n",
       "      <td>340.849</td>\n",
       "      <td>34.085</td>\n",
       "      <td>74.413719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4/1/2014</td>\n",
       "      <td>316.395</td>\n",
       "      <td>31.640</td>\n",
       "      <td>60.543402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5/1/2014</td>\n",
       "      <td>208.454</td>\n",
       "      <td>20.845</td>\n",
       "      <td>39.691514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6/1/2014</td>\n",
       "      <td>143.897</td>\n",
       "      <td>14.390</td>\n",
       "      <td>23.739326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7/1/2014</td>\n",
       "      <td>115.745</td>\n",
       "      <td>11.574</td>\n",
       "      <td>20.544896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8/1/2014</td>\n",
       "      <td>89.376</td>\n",
       "      <td>8.938</td>\n",
       "      <td>6.585640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9/1/2014</td>\n",
       "      <td>77.516</td>\n",
       "      <td>7.752</td>\n",
       "      <td>-2.201777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10/1/2014</td>\n",
       "      <td>99.797</td>\n",
       "      <td>9.980</td>\n",
       "      <td>-7.396387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11/1/2014</td>\n",
       "      <td>136.420</td>\n",
       "      <td>13.642</td>\n",
       "      <td>6.739345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12/1/2014</td>\n",
       "      <td>162.243</td>\n",
       "      <td>16.224</td>\n",
       "      <td>53.268138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  Satellite_ET  ScaledS_ET  Station_ET\n",
       "0    1/1/2013       263.876      26.388         NaN\n",
       "1    2/1/2013       324.463      32.446         NaN\n",
       "2    3/1/2013       355.000      35.500         NaN\n",
       "3    4/1/2013       262.270      26.227         NaN\n",
       "4    5/1/2013       188.725      18.873         NaN\n",
       "5    6/1/2013       128.474      12.847         NaN\n",
       "6    7/1/2013       108.482      10.848         NaN\n",
       "7    8/1/2013        74.753       7.475         NaN\n",
       "8    9/1/2013        65.583       6.558         NaN\n",
       "9   10/1/2013       107.078      10.708   -4.102158\n",
       "10  11/1/2013       156.447      15.645   17.128312\n",
       "11  12/1/2013       215.078      21.508   63.766344\n",
       "12   1/1/2014       260.057      26.006   67.850113\n",
       "13   2/1/2014       307.218      30.722   70.190364\n",
       "14   3/1/2014       340.849      34.085   74.413719\n",
       "15   4/1/2014       316.395      31.640   60.543402\n",
       "16   5/1/2014       208.454      20.845   39.691514\n",
       "17   6/1/2014       143.897      14.390   23.739326\n",
       "18   7/1/2014       115.745      11.574   20.544896\n",
       "19   8/1/2014        89.376       8.938    6.585640\n",
       "20   9/1/2014        77.516       7.752   -2.201777\n",
       "21  10/1/2014        99.797       9.980   -7.396387\n",
       "22  11/1/2014       136.420      13.642    6.739345\n",
       "23  12/1/2014       162.243      16.224   53.268138"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp.head(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a05702-a4e8-4086-a6ef-329fd1d45394",
   "metadata": {},
   "source": [
    "### 4. Getting information about data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7fe4a8-d541-4943-b02b-97a9f6d84b39",
   "metadata": {},
   "source": [
    "#### a. Check the data type and check the data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "332e068a-a29b-4b3f-83e8-95cf3420321c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Satellite_ET</th>\n",
       "      <th>ScaledS_ET</th>\n",
       "      <th>Station_ET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>188.649889</td>\n",
       "      <td>18.865028</td>\n",
       "      <td>40.389501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>88.194543</td>\n",
       "      <td>8.819452</td>\n",
       "      <td>30.630458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>64.361000</td>\n",
       "      <td>6.436000</td>\n",
       "      <td>-16.195257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>108.131000</td>\n",
       "      <td>10.813000</td>\n",
       "      <td>17.128312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>174.077000</td>\n",
       "      <td>17.407500</td>\n",
       "      <td>40.665133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>264.219250</td>\n",
       "      <td>26.422250</td>\n",
       "      <td>70.002893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>363.137000</td>\n",
       "      <td>36.314000</td>\n",
       "      <td>81.476488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Satellite_ET  ScaledS_ET  Station_ET\n",
       "count     72.000000   72.000000   53.000000\n",
       "mean     188.649889   18.865028   40.389501\n",
       "std       88.194543    8.819452   30.630458\n",
       "min       64.361000    6.436000  -16.195257\n",
       "25%      108.131000   10.813000   17.128312\n",
       "50%      174.077000   17.407500   40.665133\n",
       "75%      264.219250   26.422250   70.002893\n",
       "max      363.137000   36.314000   81.476488"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d4ef4-2a95-4852-b114-d19d3cdb3fc1",
   "metadata": {},
   "source": [
    "When we zoom in on the date (below)If you notice, the \"top\" value is not the highest frequency... All values in python are 1s as they are not equal to 0. There for any single value holds a \"top\" (1) value! The system randomly selects any value. We must convert this column \"Date\" into a datetime type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4215d73-2261-4651-9918-2ccc74e7e8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count           72\n",
       "unique          72\n",
       "top       1/1/2013\n",
       "freq             1\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp.date.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b6b92b-17f1-428a-bc31-9e1ae3c8ef76",
   "metadata": {},
   "source": [
    "#### b. Check the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d2c01b2-e992-45c6-a59f-f4b39dc674d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             object\n",
       "Satellite_ET    float64\n",
       "ScaledS_ET      float64\n",
       "Station_ET      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d07a0-1f59-44ba-a6f2-97de64719759",
   "metadata": {},
   "source": [
    "#### c. Check the data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2954429-6579-43f9-a472-7e9784677a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72 entries, 0 to 71\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   date          72 non-null     object \n",
      " 1   Satellite_ET  72 non-null     float64\n",
      " 2   ScaledS_ET    72 non-null     float64\n",
      " 3   Station_ET    53 non-null     float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 2.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_comp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8ea6fb-bd8f-408d-af93-42ed33aa906f",
   "metadata": {},
   "source": [
    "### 5. Convert the \"Date\" column to 'datetime' for Pyrhon to understand that it is a date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2d569-7294-4257-8096-a7a7ea89edbb",
   "metadata": {},
   "source": [
    "In Pandas, we have a method (to.date) we can call to convert the \"Date\" values to date from text whatever format - in this case 'object'. Also in our case, it is the entire data frame or complete data frame (df_comp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe64f6b-bdf5-4e02-a469-aa085980f0dd",
   "metadata": {},
   "source": [
    "#### Date is being converted from object to date recognisable by Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06058a5b-5d1d-4117-b26e-f28dbbf80327",
   "metadata": {},
   "source": [
    "Call the method pd.to_datetime(), as arguement enter(call) the column in question - in this case \"Date\": pd.to_datetime(df_comp.Date). The systeme (Python) assumes a string in a \"mm/dd/yyy\" form is being plugged in. Remember most dates are saved in the \"mm/dd/yyyy\"format. To get around this, a second argument is used: dayfirst = True.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc76052-7e5a-4b96-9522-cb51dbb3c36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2013-01-01\n",
       "1    2013-01-02\n",
       "2    2013-01-03\n",
       "3    2013-01-04\n",
       "4    2013-01-05\n",
       "        ...    \n",
       "67   2018-01-08\n",
       "68   2018-01-09\n",
       "69   2018-01-10\n",
       "70   2018-01-11\n",
       "71   2018-01-12\n",
       "Name: date, Length: 72, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df_comp.date, dayfirst = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dcba14-4a06-4c82-b58c-61f69190de1b",
   "metadata": {},
   "source": [
    "The column will just display the changes without actually storing the data. To store it, we designate the changes to \"df_comp.Date\" in the first line as done below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ad5d98-4430-419a-83d9-eb72d9e372a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.date = pd.to_datetime(df_comp.date, dayfirst = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1d563-cb19-489b-b058-6d9b097eb29c",
   "metadata": {},
   "source": [
    "To see what have done, we use the .head() to explore(view) the changes. See below! üòâ Here we don't see that the values are formatted differently because the dates were already in the yyyy-mm-dd format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c62a72-fea4-4fa1-83f3-971360b6c536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Satellite_ET</th>\n",
       "      <th>ScaledS_ET</th>\n",
       "      <th>Station_ET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>263.876</td>\n",
       "      <td>26.388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>324.463</td>\n",
       "      <td>32.446</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>355.000</td>\n",
       "      <td>35.500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>262.270</td>\n",
       "      <td>26.227</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>188.725</td>\n",
       "      <td>18.873</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Satellite_ET  ScaledS_ET  Station_ET\n",
       "0 2013-01-01       263.876      26.388         NaN\n",
       "1 2013-01-02       324.463      32.446         NaN\n",
       "2 2013-01-03       355.000      35.500         NaN\n",
       "3 2013-01-04       262.270      26.227         NaN\n",
       "4 2013-01-05       188.725      18.873         NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de1c8d9-7242-41e3-abc0-7ff6df4b80ee",
   "metadata": {},
   "source": [
    "To see if the \"Date\" values are no longer stored as text. We can use the .describe() method to see. Equally, the .dtypes and info() methods can work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f33b349-06c8-4c2b-8386-ea1bc0d7269d",
   "metadata": {},
   "source": [
    "We only call the method on the attribute \"Date\"we want to see:As we do not want to see the other attributes, we specify the attribute we want to see (df_comp.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0210d40-a405-45a3-8f75-5896b5ac5cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                     72\n",
       "mean     2015-07-08 08:00:00\n",
       "min      2013-01-01 00:00:00\n",
       "25%      2014-01-06 18:00:00\n",
       "50%      2015-07-08 00:00:00\n",
       "75%      2017-01-06 06:00:00\n",
       "max      2018-01-12 00:00:00\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp.date.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e45954-8279-4394-bc47-03fd110d3931",
   "metadata": {},
   "source": [
    "As you can see, now the data has been arranged with the first date on the top as it should be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4904c3c-6cf9-4153-ba14-2f4cbbe4fb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60708c3d-4a06-4111-bac8-3f2aab42c1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date            datetime64[ns]\n",
       "Satellite_ET           float64\n",
       "ScaledS_ET             float64\n",
       "Station_ET             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99c5f1-742f-4eb7-845f-59cb79f4dc4b",
   "metadata": {},
   "source": [
    "### 6. Set the \"Date\" column to be the index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69816638-6192-492e-9625-a182e64d2158",
   "metadata": {},
   "source": [
    "We are setting the  date attribute to be the referred to index. The optional argument \"inplace\", tells Python to set this new format instead of integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c2edf3a-10aa-4ace-a4fa-a08d8dd57aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.set_index('date', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfc206cb-9fd2-4236-accc-6e04b62a5051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Satellite_ET</th>\n",
       "      <th>ScaledS_ET</th>\n",
       "      <th>Station_ET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>263.876</td>\n",
       "      <td>26.388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>324.463</td>\n",
       "      <td>32.446</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>355.000</td>\n",
       "      <td>35.500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>262.270</td>\n",
       "      <td>26.227</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>188.725</td>\n",
       "      <td>18.873</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Satellite_ET  ScaledS_ET  Station_ET\n",
       "date                                            \n",
       "2013-01-01       263.876      26.388         NaN\n",
       "2013-01-02       324.463      32.446         NaN\n",
       "2013-01-03       355.000      35.500         NaN\n",
       "2013-01-04       262.270      26.227         NaN\n",
       "2013-01-05       188.725      18.873         NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp.head() #We can see that the \"Date\" is now the index and that now it will not be recognised as an attribute. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f9df7-2cc2-4333-b4d3-ef11f66b1b16",
   "metadata": {},
   "source": [
    "This time, when we try to call the date column using describe. We will see an error because the column is no longer an attribute but the index. See below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02dfe186-39be-41fb-ab22-fe72bdb08ce5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3736\\49469409.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_comp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "df_comp.date.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73766865-032b-4666-bd3f-e95f950f2563",
   "metadata": {},
   "source": [
    "### 7. Time-Series Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157b9fc-63d9-4b49-b71c-4267b3a55eef",
   "metadata": {},
   "source": [
    "#### Time series data requires a constant frequency that persists through out the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a25c0d-20c9-4aee-8b43-767c9732b9c5",
   "metadata": {},
   "source": [
    "#### a. Before we set the frequency, it is important to check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5948e-22ef-4ae3-8d38-a88b31979f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c700628-10ae-43d8-8197-e771eab12161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c749b3b-38ef-4f87-b7cf-38d116812c4b",
   "metadata": {},
   "source": [
    "Theren't any missing values for the satellite dataa prior to us setting th frequency. However, we have 19 missing values for the station data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5e8a7-d1a7-4e8f-9399-763c6bc20411",
   "metadata": {},
   "source": [
    "#### b. Set the frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a1d9e-5a26-4d69-8d32-9553533ed489",
   "metadata": {},
   "source": [
    "The frequency is set by calling the 'as frequent' (asfreq) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b4aa8-260d-4d3d-86ea-ced7ffc04576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = df_comp.asfreq('d') #The method asfreq takes alphabetical values d = day, b = business day, year = a (annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900626f-9a4a-40dc-9057-feec78114d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30620326-5d0d-41d8-8eb7-9a1f6711fba5",
   "metadata": {},
   "source": [
    "The process of assgning frequency may generate new periods, which do not have values associated with them. In this study, the besty frequency is daily 'd' as the others do not suitably bring out the data as needed. The others include: business days 'b' (which are days minus weekends and public holidays; weeks 'w'; months 'm'; years 'a' (represented by 'a' because of the use of 'annually' in place of 'yearly'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc5dd3-a747-441f-9326-81c24aad4fc3",
   "metadata": {},
   "source": [
    "### 7. Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed53671-0c1c-4c16-8ed8-64780dacce4a",
   "metadata": {},
   "source": [
    "##### First thing: Check if assigning frequency increased the dates for which data is not available. There is a dedicated method: isna() of which in our case we call on the entire data frame\n",
    "üëâüèæWe call this method on the entire data frame\n",
    "üëâüèæTrue indicates there are missing values\n",
    "üëâüèæFalse indicates there aren't. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7931125-52da-4bd8-a708-f4bdab31771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbffe9e-1bb2-44c0-b4f8-2716b44a3836",
   "metadata": {},
   "source": [
    "The bigger the dataset, the more difficult it be comes to spot missing entries. Therefore, we employ the method below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d49f599-2347-4a50-a96e-180331867684",
   "metadata": {},
   "source": [
    "#### a. Viewing all (the sum Œ£ Œøf) missing values ( the \"not available\" values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834bfdb5-cff6-4535-8431-963c7c2b551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.isna().sum() #We call the sum method .sum() - without available information(empty brackets, no arguments) in order to sum up all the Booleans! üî•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3f4cb2-78ae-43ee-ba66-8d469e8b32a3",
   "metadata": {},
   "source": [
    "As we can see, the values were not altered: Satellite data with no missing data and station data with 19 missing data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f770b-83ee-4164-aeb9-309ac7be5a8e",
   "metadata": {},
   "source": [
    "#### b. Filling in the \"not available\" data, fillna(). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cef6c56-5b38-4745-9096-5a314dc35757",
   "metadata": {},
   "source": [
    "There are three methods of filling in missing data. Front fill (ffill), back fill (bfill) & fill with the same values e.g the mean, (or median). Usually filling values using the mean is a bad approach because there are underlying values. This method is only appropriate when the data fluctuates around the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1dac1-6964-4b8b-b70c-58507b8545cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca79bb-20e9-47bb-8f92-6cde9aa1c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.Station_ET = df_comp.Station_ET.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2762d5-ff6d-4edb-b1ff-83e68a8d2ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.isna().sum() #Check new missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308853d-6a77-444d-b874-b3cf10db0a84",
   "metadata": {},
   "source": [
    "We can see that from 19, the number has reduced to only 9 instances after front filling. This is due to the nature of the data which has no data in front. \n",
    "\n",
    "#### To assign a constant value, we do not need an argument but a number (value)\n",
    "\n",
    "In this instance, we try the mean. The reason why the mean is not advised is explained in the earlier sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b130d-842f-48b9-8f08-e6cc1fe8c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comp.Station_ET  = df_comp.Station_ET.fillna(value = df_comp.Station_ET.mean())\n",
    "#df_comp.ScaledS_ET  = df_comp.ScaledS_ET.fillna(method = 'ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d76c7-6878-4821-99db-d503a1c9299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec6439-8ace-4c2b-90b4-11813cf57191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the mean method (()) clears all instances to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c681b-9c89-4da0-9ca3-415dc89d0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comp.ScaledS_ET  = df_comp.ScaledS_ET.fillna(method = 'bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ce8b3-d03d-4adf-82a8-10f279b38e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8abcf74-f45d-4877-90d9-995ccaf036d6",
   "metadata": {},
   "source": [
    "### Let's try to analyse the data for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a883f-54de-4756-a79c-b79cd8b1226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25838c-ac54-4105-8568-5971865dfb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c023f8-d862-4b53-8d92-9ad8e92e4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ee9f9-abc0-431f-86f4-54fd49ec556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_comp['Station_ET'])\n",
    "plt.savefig(\"Serenje Station Outliers Data.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84909886-b1fe-43e9-9f4e-52a26e965133",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_comp['ScaledS_ET'])\n",
    "plt.savefig(\"Serenje Station Outliers Data1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a59be-1f98-424f-af6e-38d1393f8079",
   "metadata": {},
   "source": [
    "To see the outliers clearly we use box plots by calling on our column of interest from the sns package\n",
    "\n",
    "    boxplot(DATA FRAME [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325af14f-b37b-45bf-bc86-ee47a32d2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df_comp['ScaledS_ET'])\n",
    "plt.savefig(\"Serenje_Sat_Outliers_BoxPlot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ce920-99da-4b21-bf5f-ca9c2ab10a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df_comp['ScaledS_ET'])\n",
    "plt.savefig(\"Serenje Station Outliers BoxPlot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281b55ab-87d6-40c9-ba20-0e83ed165f90",
   "metadata": {},
   "source": [
    "There seems to be not outliers but here is the method to remove outliers if there are there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cedb2d-75ca-4459-9808-1edebaf90711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c269c4-3a25-491a-9de4-9a14d560b2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e1835a0-13e3-4eda-a9f6-d4397d918f03",
   "metadata": {},
   "source": [
    "#### Adding or Removing Columns (Just in case)\n",
    "\n",
    "In time sereis we often end up analyzing one sequence by its own. In this case, we are going to narrow down to the Station_ET. \n",
    "\n",
    "üëâüèæ We remove data for several reasons 1. load less data at a time (this may not be a problem as the data  is not much) 2. Clarity                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c1b597-3c9c-43f2-9b51-e77536c869d8",
   "metadata": {},
   "source": [
    "##### Before we remove any data, we will create a column called MOD16A2 and assign it with the same values as ScaledS_ET\n",
    "\n",
    "This column makes things much more convenient as it allows us, by changing a single line, to resuse the entire code to analyze to analyze a different time series. \n",
    "\n",
    "üëáüèæ Here below is how it is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040a709-88a6-42c0-92e6-9434117161cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp['MOD16A2'] = df_comp.ScaledS_ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a965fc4-5a1f-45c7-be17-da2f09087766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5e2fc1-9f37-4923-915c-efd7212fd825",
   "metadata": {},
   "source": [
    "üìå Since it has the same values as ScaledS_ET, the summerized statistics for the two are identical. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb2238-d65c-434b-9e65-5f8d46e9099b",
   "metadata": {},
   "source": [
    "#### Deleting\n",
    "\n",
    "Now to delete a specifi column from the data frame, we use the following method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c828d-ecd6-4684-8c2b-9c52317251ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_comp['Satellite_ET'],\n",
    "del df_comp['ScaledS_ET'],\n",
    "del df_comp['Station_ET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c1697-7dbc-471c-a022-a83209853884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d283afe8-1a6d-4d5d-ac08-e506dbcc722f",
   "metadata": {},
   "source": [
    "### Processing of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ba1d0-b968-4754-bd1f-76a1f879bc0d",
   "metadata": {},
   "source": [
    "#### 1. Splitting of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff70f7-7128-4f49-9b60-b19196863b88",
   "metadata": {},
   "source": [
    "#### For successful machineü§ñ learning, we need to split the available data into two sets: \n",
    "üëâüèæ A training set and a testing set. The goal is to have the option of feeding new information into the model and comparing its predictions to actual values. The closer the forecasts match our value, the better the model performs.\n",
    "\n",
    "For many ML methods we shuffle the data before splitting it however TS however time series data relies in keeping the chronological order of values within a setk. This unfortunately, makes shuffling impossible.\n",
    "\n",
    "Since we cannot shuffle, the training and the testing set should be uninterupted sequences of values. \n",
    "\n",
    "The training set should include data from the beginning of a set, up to a specific point in time while the testing set - the rest. \n",
    "üëâüèæ The appropriate size of the training set is debatable, if it is too long, the model will fit the actual data too well and will perform poorly with the new data. \n",
    "\n",
    "üëâüèæIf it is too small, we won't be able to create a model accurate enough. \n",
    "\n",
    "üéº In this study, an 80%:20% is used (which is reasonable). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516814fd-5beb-46f8-9598-510a5f8caf62",
   "metadata": {},
   "source": [
    "##### Use the \"iloc\" method (coming from the index location) which slices the data\n",
    "üëâüèæ We must know where the first set begins and where the second one begins \n",
    "üëâüèæ In other words, we must determine the cutoff point point. \n",
    "\n",
    "To achieve this, we use the \"len\" function which returns the length of an object in Python. \n",
    "üëâüèæ Let's define an integer (int) variable called size which defines how long the training set should be. As stated before, we want to use approximately 80% of the entire data set: the result will be the length of the training set. \n",
    "\n",
    "Use the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42dc0ee-9aed-4420-a712-d23c7ee07999",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(df_comp)*0.8)\n",
    "# df, df_test = df_comp.iloc[:size], df_comp.iloc[size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661f26e-2164-481b-b1de-d301577561d9",
   "metadata": {},
   "source": [
    "After determining where the training should end, we should now use the \"iloc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d62d37-33f8-4250-91e0-f28da15c6606",
   "metadata": {},
   "source": [
    "Training set will be named \"df\". the \"df\" is short hand to save time as we will refer to it a lot. \n",
    "Testing set will be name \"df_test\".\n",
    "\n",
    "We refer df up to the size value ( which as defined above is an integer taking 80% of the entire data frameüëçüèæ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a6774-eaa8-4fbe-8723-c97dc5332660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_comp.iloc[size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757250a-e152-412b-b0fe-44123d3ae53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_comp.iloc[size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92501d46-ee58-4741-a659-99b3d162a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_test = df_comp.iloc[:size], df_comp.iloc[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba50234-f499-4c59-816d-8b2ded3b66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c1f5d-4900-4b4b-b214-8e38204eaf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb816e-c3ab-4586-9fb0-11f47b874592",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Lesson from code basic\n",
    "\n",
    "Date Time Index and resampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73802568-e33c-4d3b-9ab5-f4edabf7c6bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (3752675155.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    df_comp[2013-01-01]\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbadc96f-a88e-4e8c-8eaf-e0f8ac8a8bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28bc942-9ab4-401a-aecb-205b0876c1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29a07c7-581b-4e48-84f2-76cc93621e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e6de2-6191-4b19-bf6a-5848e84231a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10dca53d-063e-4374-9949-f656598b53fa",
   "metadata": {},
   "source": [
    "## Temperature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7341178-5058-4e49-8965-15923a627259",
   "metadata": {},
   "source": [
    "### De-trending and modelling seasonal variation with Fourier Series\n",
    "\n",
    "### T seasonal = a0 + Œ£iŒ±isin(iœâ1t +Œ∏) + Œ£iŒ≤icos(iœâ2t + œÜ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ae739-a846-40f4-aebf-15e79d4d7545",
   "metadata": {},
   "source": [
    "#### Time series decomposition\n",
    "\n",
    "Technique that splits a time series into several components, each representing an underlying pattern category\n",
    "\n",
    "    yt = Tt + St + et\n",
    "\n",
    "1. Trend: decreasing or increasing over time.\n",
    "2. Seasonality: periodic signal.\n",
    "3. Noise: variability in data that the model can't explain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3affac-c87e-4f0d-81f3-35a0bb310474",
   "metadata": {},
   "outputs": [],
   "source": [
    "Denoised DAT series\n",
    "\n",
    "Denoise to see trend and overall pick. \n",
    "\n",
    "Method usually used: Convolutions \n",
    "\n",
    "(f*g)(x) = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472862df-8248-4aa9-b691-476518c3edcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe22d4-b699-4123-ada0-9de5df779887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767a47f-4a06-4dca-9485-096fd0c5b7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "446be74b-e5a7-4a2f-a259-dde71eddb601",
   "metadata": {},
   "source": [
    "## Main approaches for mathematical modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fffa58-f16a-4cca-a590-e9f710ea435a",
   "metadata": {},
   "source": [
    "### White Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1d09b-dcce-4190-9970-95da8dfcd9d0",
   "metadata": {},
   "source": [
    "#### üôãüèæ‚Äç‚ôÇÔ∏è What at is it? Why do we need it?\n",
    "What noise is special type of TS, where the data doesn't follow a pattern. \n",
    "\n",
    "üí°A recap of TS is that, data in the past, also persists in the future (training:test).\n",
    "    üëâüèæ In this case, since no pattern can be found, the data is unpredictable. \n",
    "    üëâüèæ In order for a series to be considered as 'white noise', it must satisfy the following three conditions:\n",
    "        ‚úî Œº   - the mean must be constant\n",
    "        ‚úî œÉ^2 - constant standard deviations\n",
    "        ‚úî     - no autocorrelation in any period: This means that there is no clear relationship between past and present values. \n",
    "\n",
    "The first two ideas are straight forward, on the third, we need to try and iterate a little more. \n",
    "\n",
    "œÅ = corr( xt, xt-1)\n",
    "\n",
    "##### White Noise is a sequence of random data, whree every value has a time-period associated with it\n",
    "üëâüèæWe can say it behaves sporadically, hence there is no prediction into the future. \n",
    "\n",
    "Dictionary üìñ\n",
    "œÅ œÉ Œº Œª Œ£ œÜ Œ¶ Œ≥ Œì "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84dbc25-b89f-4f59-ab4e-c3c1e0fb0965",
   "metadata": {},
   "source": [
    "In (financial) modelling, it is important to distinguish between white noise data and regular TS data. We can easily tell the two apart by comparing  their graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a1a83-2cb4-4e0e-813a-d01ab634be77",
   "metadata": {},
   "source": [
    "wn = np.random.normal() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c41d7-6d22-4f7d-b3ff-6e7747aa0e28",
   "metadata": {},
   "source": [
    "This will create an array of values in a 'Normal' distribution \n",
    "\n",
    "    [x1, x2, x3, ..., xn]\n",
    "    X ~ N(Œº, œÉ^2)\n",
    "\n",
    "If we want this series to be compared to the actual sequence, we should set its mean and standard deviation to that of the actual sequence data set. \n",
    "\n",
    "    X ~ N(ŒºMOD, œÉ^2MOD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc3eeb-a8f5-465c-877f-58b29fdb9435",
   "metadata": {},
   "source": [
    "the location argument of the method loc, takes numbers of the average point of the distribution\n",
    "    (loc = df.MOD16A2.mean(), scale = df.MOD16A2.std())\n",
    "\n",
    "Before calling the method, we define how many values we want it to generate. If we want the sequence to serve as a good comparison, it should have \n",
    "as many elements (values) as our time series. \n",
    "\n",
    "so let's set the size argument as shown below:\n",
    "\n",
    "  loc = df.MOD16A2.mean(), scale = df.MOD16A2.std(), size = len(df) then run the cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4b85e-b91c-4059-9165-dec9910a781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = np.random.normal(loc = df.MOD16A2.mean(), scale = df.MOD16A2.std(), size = len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9b5c6-fd87-4eea-8bdb-4cd5f2ea13d1",
   "metadata": {},
   "source": [
    "#### We now add the White Noise to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c05fc5-3569-4d52-a3b3-c52f30899d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['White_Noise'] = wn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ccd19c-7652-453f-986f-19b822e48e82",
   "metadata": {},
   "source": [
    "üí° Every value of the WN sequence will be assigned a time period since the df uses dates as indices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3f667-ff61-409a-88ab-a16f823bc71b",
   "metadata": {},
   "source": [
    "‚òùüèæ The ‚ö† message above will be  discussed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d244b3d-b6b6-4bcf-b94e-30e595638d4f",
   "metadata": {},
   "source": [
    "Let's how the data frame looks like after adding a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44e168-8dff-424e-96fc-86daa579b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f6964a-4e98-4147-bf15-b0982c1ff566",
   "metadata": {},
   "source": [
    "##### üö¶ Notice that that the mean of the series (MOD16A2) is similar to that of the White Noise\n",
    "\n",
    "This is because the White Noise is generated around the meanof MOD16A2. However, since each data set is generated separately, the mean cannot be the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcebe2da-17ea-45c3-b2ea-6dc24f8ad352",
   "metadata": {},
   "source": [
    "##### Let's now name and plot it. It is important ot name to avoid mistakes when extracting insights\n",
    "\n",
    "It's important to note that the size method is assigned a number to make the size distinguishable. \n",
    "\n",
    "We also call the figure size (figsize) to stretch the graph and be able to observe the values clearly. figsize is an argument of the plot method plt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a713df79-b2f8-4181-a8a5-22b791d71785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.White_Noise.plot(figsize =(15, 3.5))\n",
    "plt.title(\"White Noise Time-Series\", size = 24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209fc73-4e74-4377-bc2f-bf0e6d0cd80d",
   "metadata": {},
   "source": [
    "##### We now plot the MOD16A2 data with similar criteria to make the two graphs comparable \n",
    "If the graphs are different (i.e the y axis), we can modify the respective graph to match the other one using this code: \n",
    "    plt.ylin(a, b) where a is the lower limit and b is the upper limit. In this case, everythin looks in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda0008-106f-45ae-b3dd-039ef4446f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MOD16A2.plot(figsize =(15, 3.5))\n",
    "plt.title(\"MOD16A2-Satellite Evaporation\", size = 24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c511b4c-6232-4bca-8399-6a9a68a4d71d",
   "metadata": {},
   "source": [
    "##### üí°Looking at the two graphs, the WN graph has more jumps towards the data showing the randomness while the actual MPD16A2 data has even spikes which \n",
    "indicate a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdbbef-620a-4244-8224-98a0119a9070",
   "metadata": {},
   "source": [
    "Let's join the two graphs in a White Noise vs MOD16A2 graph, add a lengend and download this figure using the two lines of code below: \n",
    "\n",
    "plt.legend(loc = [.2, .2]);\n",
    "plot.savefig(\"MOD16A2 and Noise comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da6eaa0-96b0-406f-af9f-595b9f33c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.White_Noise.plot(figsize =(15, 3.5))\n",
    "df.MOD16A2.plot(figsize =(15, 3.5))\n",
    "plt.title(\"White Noise vs MOD16A2\", size = 24)\n",
    "plt.show()\n",
    "#plt.legend(loc = [.2, .2]);\n",
    "plt.savefig(\"MOD16A2 and Noise comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01360b60-0a5a-4d9d-8bae-b0cff9073e86",
   "metadata": {},
   "source": [
    "üí°üö¶ See the trend in the orange line and the randomness of the blue line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf8d1eb-53e7-49c6-981b-eb3636d373a5",
   "metadata": {},
   "source": [
    "### Random walk\n",
    "\n",
    "As special type of time-series, where values tend to persist over time and the differences between periods are simply white noise. \n",
    "\n",
    "Take the scenario below:\n",
    "\n",
    "Pt = Pt-1 + Œµt, where P: prices Œµt: residuals ~ WN(Œº,œÉ^2) - cannot be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e2efc-23d6-4a10-a067-627cce27fa0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15476899-8eb3-4f75-8eec-e7a56b1a4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rw = \n",
    "# rw.date = pd.to_datetime(rw.date, dayfirst = True)\n",
    "# rw.set_index('Date', inplace= True)\n",
    "# rw = rw.asfreq('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32bb5aa-1077-4bea-a43f-109a97f0813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[Random_Walk] = rw.Station_ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf98ce-cebd-4fb0-85fa-156dba061252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38353db-bdb4-4c7f-86b7-2c482d28d80f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379ed3c-5eb9-470b-b749-cc5db4310cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate whitel noise [x1, x2, x3, ..., xn] X~N(Œº, œÉ^2)\n",
    "wn = np.random.normal(loc = df.Uscaled_Sat_ET.mean(), scale = df.Uscaled_Sat_ET.std(), size = len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1714b-a69e-4f75-8219-c96971eda910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try adding the white noise to the data frame\n",
    "df['wn'] = wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71e755-b69b-4a55-9d18-296b25958183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d3607-dfd2-45a4-b62e-8d151895b9e6",
   "metadata": {},
   "source": [
    "#White Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b101581-3427-487d-9eea-10add579ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wn.plot(figsize = (20,5))\n",
    "plt.title('White Noise Time-Series', size = 24)\n",
    "plt.show()\n",
    "plt.savefig(\"White Noise Time-Series.png\", dpi = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd404e81-0879-450a-b7e0-80fecf0250bd",
   "metadata": {},
   "source": [
    "#### saving the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba287f60-1524-4cce-8144-ccc4ecd33608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.savefig(\"White Noise Time-Series.png\", dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9fb456-b428-4951-b8d5-0391613f4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Uscaled_Sat_ET.plot(figsize = (20, 5))\n",
    "plt.title('Evaporation Trend*', size =24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f793c-f731-46e6-99b7-428325e8042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wn.plot(figsize = (20,5))\n",
    "df.Uscaled_Sat_ET.plot(figsize = (20, 5))\n",
    "plt.title('Evaporation Trend* v White Noise', size =24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec05751-365c-4541-bbd2-6ebe5225ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pt = Pt-1 + Œµt, P: prics Œµt: residuals = WN(Œº,œÉ^2) - cannot be predicted\n",
    "# rw = pd.read_csv('RandWalk.csv')\n",
    "# rw.date = pd.to_datetime(rw.date, dayfirst = True)\n",
    "# rw.set_index('Date', inplace= True)\n",
    "# rw = rw.asfreq('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d0480-bc59-4e78-9ea9-7967bd26902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71c5c5-244f-48a3-9ab7-824cde83ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certain trends will appear in a cyclical manner\n",
    "# Decompose the Time Series in to three effects\n",
    "s_dec_additive = seasonal_decompose(df.Uscaled_Sat_ET, model = \"additive\")\n",
    "s_dec_additive.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc22bdf-f1a0-4de5-9f49-5a12fd8403a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certain trends will appear in a cyclical manner\n",
    "# Decompose the Time Series in to three effects\n",
    "s_dec_additive = seasonal_decompose(df.Uscaled_Sat_ET, model = \"multiplicative\")\n",
    "s_dec_additive.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7719589-6569-463b-9fe7-e51f16b6af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The trend is similar to  the observed series because: because the decomposition function uses the previous period values as a trend setter\n",
    "#Values oscillating back and forth and the (scale) of the figure is too small to observe this change.No cyclic pattern determined    \n",
    "# turn of the century and 2008. .com babble and housing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b303c47-b078-4b58-958a-01c0fea659e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
